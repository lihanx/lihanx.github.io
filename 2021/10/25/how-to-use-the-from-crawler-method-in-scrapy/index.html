
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Xavier&#39;s Blog">
    <title>Scrapy 中的 from_crawler() 方法应该怎么用? - Xavier&#39;s Blog</title>
    <meta name="author" content="Xavier">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Xavier","sameAs":["https://github.com/lihanx","mailto:lihanx9@163.com"],"image":"profile.jpg"},"articleBody":"\n\n零、前言Crawler 类是 Scrapy 中的一个核心组件, 很多其他组件通过实现 from_crawler() 方法与 Crawler 类建立起联系.from_crawler() 方法为爬虫各组件提供了强大的功能扩展支持.本文将结合源码，对from_crawler()方法进行梳理总结.\n全文主要围绕以下几个问题:\n\n哪些组件可以使用 from_crawler() 方法?\n在 from_crawler()  中都可以实现哪些功能?\nfrom_crawler() 方法是怎么被调用的?\n\n\n\n\n一、哪些组件可以使用 from_crawler() 方法首先，常用的组件有：\n\nDupeFilter\nScheduler\nMiddlewares\nPipelines\nExtensions\nSpider\n\n根据场景，不常用的组件有：\n\ndownloader.handlers\nqueues\ndns resolver\nlog formatter\n\n常用组件其实可以参考 scrapy_redis 的实现，很容易就可以看到相关的用法.\n或者可以参考 scrapy 本身模块的实现，项目中可参考的模块有：\n\nscrapy.dupefilter\nscrapy.core.scheduler\nscrapy.downloadermiddlewares\nscrapy.spidermiddlewares\nscrapy.core.downloader.handlers\nscrapy.squeues\nscrapy.resolver\n\n\n\n二、在 from_crawler() 方法中都可以实现哪些功能首先，from_crawler() 最核心的一个目的，是创建并返回其所在类的实例。\n比如自己实现 Spider 时，所继承的父类 scrapy.Spider中:\n123456789class Spider(object_ref):    ...    @classmethod    def from_crawler(cls, crawler, *args, **kwargs):        # 创建所在类的实例并返回        spider = cls(*args, **kwargs)        spider._set_crawler(crawler)        return spider    ...\n\n\n这里有个相关的知识点：类方法\n\n其次，由于必须传入crawler 实例作为参数，那么我们可以对 crawler 携带的属性加以利用。  \n比如内置的爬虫中间件 scrapy.spidermiddlewares.depth.DepthMiddleware：\n在 from_crawler() 中获取 settings 中的配置项，将其作为实例属性绑定到中间件实例中\n123456789101112131415161718class DepthMiddleware:    def __init__(self, maxdepth, stats, verbose_stats=False, prio=1):        self.maxdepth = maxdepth        self.stats = stats        self.verbose_stats = verbose_stats        self.prio = prio    @classmethod    def from_crawler(cls, crawler):        # 可以获取 crawler.settings 中的配置项，在实例化时作为参数传入        settings = crawler.settings        maxdepth = settings.getint(&#x27;DEPTH_LIMIT&#x27;)        verbose = settings.getbool(&#x27;DEPTH_STATS_VERBOSE&#x27;)        prio = settings.getint(&#x27;DEPTH_PRIORITY&#x27;)        return cls(maxdepth, crawler.stats, verbose, prio)          ...\n\n\n\n另外，由于 scrapy 提供了信号的支持, 并且 Crawler 实例中绑定了一个 signals 属性。那么，我们可以 利用信号机制在特定时机执行特定的操作。\n比如 Scrapy 文档 - Signals 一节给出的爬虫示例:\nfrom_crawler() 定义了在爬虫结束时，执行 spider_closed（）方法，输出日志\n12345678910111213141516171819class DmozSpider(Spider):    name = &quot;dmoz&quot;    allowed_domains = [&quot;dmoz.org&quot;]    start_urls = [        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;,        &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;,    ]    @classmethod    def from_crawler(cls, crawler, *args, **kwargs):        spider = super(DmozSpider, cls).from_crawler(crawler, *args, **kwargs)        # 绑定 spider_closed 方法到信号 signals.spider_closed        # 使其爬虫结束时触发执行        crawler.signals.connect(spider.spider_closed, signal=signals.spider_closed)        return spider          def spider_closed(self, spider):        spider.logger.info(&#x27;Spider closed: %s&#x27;, spider.name)    ...\n\n\n更多 Crawler 的 API 见文档 Crawler API\n三、from_crawler() 方法是怎样被调用的在上述示例中，直接在类里面声明了 from_crawler() 方法，它们会直接被 scrapy 内部流程中被调用。\n那么具体调用过程是什么样的呢？\n上面已经说过，类方法 from_crawler() 的主要功能是创建并返回类的实例，那么只要找到这些组件实例化的位置，就能看到 from_crawler() 被调用的过程。\n这些组件被实例化，主要是通过两种方式：\n\n直接调用 from_crawler() 进行实例化\n通过 scrapy.util.misc.create_instance() 函数进行实例化\n\n首先说 1. 直接调用 from_crawler() 进行实例化。\n典型的示例如 scrapy.crawler.Crawler 中，对爬虫类 Spider 进行实例化的过程：\n1234567891011121314151617181920212223242526272829class Crawler:   ...     @defer.inlineCallbacks    def crawl(self, *args, **kwargs):        if self.crawling:            raise RuntimeError(&quot;Crawling already taking place&quot;)        self.crawling = True        try:            self.spider = self._create_spider(*args, **kwargs)            self.engine = self._create_engine()            start_requests = iter(self.spider.start_requests())            yield self.engine.open_spider(self.spider, start_requests)            yield defer.maybeDeferred(self.engine.start)        except Exception:            self.crawling = False            if self.engine is not None:                yield self.engine.close()            raise    def _create_spider(self, *args, **kwargs):        # 这里直接调用了 spidercls 的 from_crawler 方法，获取 spidercls 的实例        return self.spidercls.from_crawler(self, *args, **kwargs)    def _create_engine(self):        return ExecutionEngine(self, lambda _: self.stop())          ...\n\n\n\n在 scrapy 中用到最多的是第二种，通过create_instance() 函数进行实例化.\n调用的实例如 scheduler 实例化 dupefilter 的过程：\n12345678910111213141516171819202122232425class Scheduler:    ...        @classmethod    def from_crawler(cls, crawler):        settings = crawler.settings        dupefilter_cls = load_object(settings[&#x27;DUPEFILTER_CLASS&#x27;])        # 这里使用 create_instance 对 dupefilter_cls 进行实例化        dupefilter = create_instance(dupefilter_cls, settings, crawler)        pqclass = load_object(settings[&#x27;SCHEDULER_PRIORITY_QUEUE&#x27;])        if pqclass is PriorityQueue:            warnings.warn(&quot;SCHEDULER_PRIORITY_QUEUE=&#x27;queuelib.PriorityQueue&#x27;&quot;                          &quot; is no longer supported because of API changes; &quot;                          &quot;please use &#x27;scrapy.pqueues.ScrapyPriorityQueue&#x27;&quot;,                          ScrapyDeprecationWarning)            from scrapy.pqueues import ScrapyPriorityQueue            pqclass = ScrapyPriorityQueue        dqclass = load_object(settings[&#x27;SCHEDULER_DISK_QUEUE&#x27;])        mqclass = load_object(settings[&#x27;SCHEDULER_MEMORY_QUEUE&#x27;])        logunser = settings.getbool(&#x27;SCHEDULER_DEBUG&#x27;)        return cls(dupefilter, jobdir=job_dir(settings), logunser=logunser,                   stats=crawler.stats, pqclass=pqclass, dqclass=dqclass,                   mqclass=mqclass, crawler=crawler)    ...\n\n\n\n那么我们来看下 create_instance 函数内部的实现:\n123456789101112131415161718192021222324252627282930313233def create_instance(objcls, settings, crawler, *args, **kwargs):    &quot;&quot;&quot;Construct a class instance using its ``from_crawler`` or    ``from_settings`` constructors, if available.    At least one of ``settings`` and ``crawler`` needs to be different from    ``None``. If ``settings `` is ``None``, ``crawler.settings`` will be used.    If ``crawler`` is ``None``, only the ``from_settings`` constructor will be    tried.    ``*args`` and ``**kwargs`` are forwarded to the constructors.    Raises ``ValueError`` if both ``settings`` and ``crawler`` are ``None``.    .. versionchanged:: 2.2       Raises ``TypeError`` if the resulting instance is ``None`` (e.g. if an       extension has not been implemented correctly).    &quot;&quot;&quot;    if settings is None:        if crawler is None:            raise ValueError(&quot;Specify at least one of settings and crawler.&quot;)        settings = crawler.settings    if crawler and hasattr(objcls, &#x27;from_crawler&#x27;):        instance = objcls.from_crawler(crawler, *args, **kwargs)        method_name = &#x27;from_crawler&#x27;    elif hasattr(objcls, &#x27;from_settings&#x27;):        instance = objcls.from_settings(settings, *args, **kwargs)        method_name = &#x27;from_settings&#x27;    else:        instance = objcls(*args, **kwargs)        method_name = &#x27;__new__&#x27;    if instance is None:        raise TypeError(f&quot;&#123;objcls.__qualname__&#125;.&#123;method_name&#125; returned None&quot;)    return instance\n\n\n\n逻辑非常清晰明了，根据条件判断调用类的 from_crawler() 方法 或 from_settings() 方法，对类进行实例化，并返回。\n同时，这里也可以看到另一个常见的类方法—— from_settings() ，有着和 from_crawler() 相似的作用。\n但是如果一个组件是通过 create_instance() 被实例化的, 并且组件内又同时实现了 from_crawler() 和 from_settings() 方法，那么将只有 from_crawler() 方法被调用。\n至此, 我们可以对 Scrapy 中常用的 from_crawler() 方法有一个基本的认识.\n\n\n四、参考资料[1] Scrapy documentation[2] Scrapy 源码","dateCreated":"2021-10-25T16:00:00+00:00","dateModified":"2022-01-09T14:11:48+00:00","datePublished":"2021-10-25T16:00:00+00:00","description":"","headline":"Scrapy 中的 from_crawler() 方法应该怎么用?","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"},"publisher":{"@type":"Organization","name":"Xavier","sameAs":["https://github.com/lihanx","mailto:lihanx9@163.com"],"image":"profile.jpg","logo":{"@type":"ImageObject","url":"profile.jpg"}},"url":"https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/","keywords":"Python, Scrapy"}</script>
    <meta property="og:type" content="blog">
<meta property="og:title" content="Scrapy 中的 from_crawler() 方法应该怎么用?">
<meta property="og:url" content="https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/index.html">
<meta property="og:site_name" content="Xavier&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-10-25T16:00:00.000Z">
<meta property="article:modified_time" content="2022-01-09T14:11:48.781Z">
<meta property="article:author" content="Xavier">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Scrapy">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="https://lihanx.github.io/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-xauyfozqtqozcpsrphukridnjkr9dhe8pwadzdb0xqjt4tr2luvsk6bxwf84.min.css">

    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Xavier&#39;s Blog
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Xavier</h4>
                
                    <h5 class="sidebar-profile-bio"></h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="分类"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分类</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/lihanx"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:lihanx9@163.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Scrapy 中的 from_crawler() 方法应该怎么用?
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2021-10-25T16:00:00+00:00">
	
		    2021年 10月 25日
    	
    </time>
    
        <span>发布在 </span>
        
    <a class="category-link" href="/categories/Scrapy/">Scrapy</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <!-- excerpt -->

<h2 id="零、前言"><a href="#零、前言" class="headerlink" title="零、前言"></a>零、前言</h2><p><code>Crawler</code> 类是 Scrapy 中的一个核心组件, 很多其他组件通过实现 <code>from_crawler()</code> 方法与 <code>Crawler</code> 类建立起联系.<br><code>from_crawler()</code> 方法为爬虫各组件提供了强大的功能扩展支持.<br>本文将结合源码，对<code>from_crawler()</code>方法进行梳理总结.</p>
<p>全文主要围绕以下几个问题:</p>
<ol>
<li>哪些组件可以使用 <code>from_crawler()</code> 方法?</li>
<li>在 <code>from_crawler()</code>  中都可以实现哪些功能?</li>
<li><code>from_crawler()</code> 方法是怎么被调用的?</li>
</ol>
<br/>


<h2 id="一、哪些组件可以使用-from-crawler-方法"><a href="#一、哪些组件可以使用-from-crawler-方法" class="headerlink" title="一、哪些组件可以使用 from_crawler() 方法"></a>一、哪些组件可以使用 <code>from_crawler()</code> 方法</h2><p>首先，常用的组件有：</p>
<ul>
<li><code>DupeFilter</code></li>
<li><code>Scheduler</code></li>
<li><code>Middlewares</code></li>
<li><code>Pipelines</code></li>
<li><code>Extensions</code></li>
<li><code>Spider</code></li>
</ul>
<p>根据场景，不常用的组件有：</p>
<ul>
<li><code>downloader.handlers</code></li>
<li><code>queues</code></li>
<li><code>dns resolver</code></li>
<li><code>log formatter</code></li>
</ul>
<p>常用组件其实可以参考 <code>scrapy_redis</code> 的实现，很容易就可以看到相关的用法.</p>
<p>或者可以参考 scrapy 本身模块的实现，项目中可参考的模块有：</p>
<ul>
<li><code>scrapy.dupefilter</code></li>
<li><code>scrapy.core.scheduler</code></li>
<li><code>scrapy.downloadermiddlewares</code></li>
<li><code>scrapy.spidermiddlewares</code></li>
<li><code>scrapy.core.downloader.handlers</code></li>
<li><code>scrapy.squeues</code></li>
<li><code>scrapy.resolver</code></li>
</ul>
<br/>

<h2 id="二、在-from-crawler-方法中都可以实现哪些功能"><a href="#二、在-from-crawler-方法中都可以实现哪些功能" class="headerlink" title="二、在 from_crawler() 方法中都可以实现哪些功能"></a>二、在 <code>from_crawler()</code> 方法中都可以实现哪些功能</h2><p>首先，<code>from_crawler()</code> 最核心的一个目的，是<strong>创建并返回其所在类的实例</strong>。</p>
<p>比如自己实现 Spider 时，所继承的父类 <code>scrapy.Spider</code>中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>(<span class="params">object_ref</span>):</span></span><br><span class="line">    ...</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="comment"># 创建所在类的实例并返回</span></span><br><span class="line">        spider = cls(*args, **kwargs)</span><br><span class="line">        spider._set_crawler(crawler)</span><br><span class="line">        <span class="keyword">return</span> spider</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里有个相关的知识点：类方法</p>
</blockquote>
<p>其次，由于必须传入<code>crawler</code> 实例作为参数，那么我们可以<strong>对 <code>crawler</code> 携带的属性加以利用</strong>。  </p>
<p>比如内置的爬虫中间件 <code>scrapy.spidermiddlewares.depth.DepthMiddleware</code>：</p>
<p><em>在 <code>from_crawler()</code> 中获取 settings 中的配置项，将其作为实例属性绑定到中间件实例中</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DepthMiddleware</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, maxdepth, stats, verbose_stats=<span class="literal">False</span>, prio=<span class="number">1</span></span>):</span></span><br><span class="line">        self.maxdepth = maxdepth</span><br><span class="line">        self.stats = stats</span><br><span class="line">        self.verbose_stats = verbose_stats</span><br><span class="line">        self.prio = prio</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        <span class="comment"># 可以获取 crawler.settings 中的配置项，在实例化时作为参数传入</span></span><br><span class="line">        settings = crawler.settings</span><br><span class="line">        maxdepth = settings.getint(<span class="string">&#x27;DEPTH_LIMIT&#x27;</span>)</span><br><span class="line">        verbose = settings.getbool(<span class="string">&#x27;DEPTH_STATS_VERBOSE&#x27;</span>)</span><br><span class="line">        prio = settings.getint(<span class="string">&#x27;DEPTH_PRIORITY&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> cls(maxdepth, crawler.stats, verbose, prio)</span><br><span class="line">      </span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>



<p>另外，由于 scrapy 提供了信号的支持, 并且 <code>Crawler</code> 实例中绑定了一个 <code>signals</code> 属性。那么，我们可以 <strong>利用信号机制在特定时机执行特定的操作</strong>。</p>
<p>比如 <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/signals.html">Scrapy 文档 - Signals</a> 一节给出的爬虫示例:</p>
<p><em><code>from_crawler()</code> 定义了在爬虫结束时，执行 <code>spider_closed（）</code>方法，输出日志</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozSpider</span>(<span class="params">Spider</span>):</span></span><br><span class="line">    name = <span class="string">&quot;dmoz&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;dmoz.org&quot;</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot;</span>,</span><br><span class="line">        <span class="string">&quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&quot;</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler, *args, **kwargs</span>):</span></span><br><span class="line">        spider = <span class="built_in">super</span>(DmozSpider, cls).from_crawler(crawler, *args, **kwargs)</span><br><span class="line">        <span class="comment"># 绑定 spider_closed 方法到信号 signals.spider_closed</span></span><br><span class="line">        <span class="comment"># 使其爬虫结束时触发执行</span></span><br><span class="line">        crawler.signals.connect(spider.spider_closed, signal=signals.spider_closed)</span><br><span class="line">        <span class="keyword">return</span> spider</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_closed</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        spider.logger.info(<span class="string">&#x27;Spider closed: %s&#x27;</span>, spider.name)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>


<p><em>更多 <code>Crawler</code> 的 API 见文档 <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/api.html#crawler-api">Crawler API</a></em></p>
<h2 id="三、from-crawler-方法是怎样被调用的"><a href="#三、from-crawler-方法是怎样被调用的" class="headerlink" title="三、from_crawler() 方法是怎样被调用的"></a>三、<code>from_crawler()</code> 方法是怎样被调用的</h2><p>在上述示例中，直接在类里面声明了 <code>from_crawler()</code> 方法，它们会直接被 scrapy 内部流程中被调用。</p>
<p>那么具体调用过程是什么样的呢？</p>
<p>上面已经说过，类方法 <code>from_crawler()</code> 的主要功能是创建并返回类的实例，那么只要找到这些组件实例化的位置，就能看到 <code>from_crawler()</code> 被调用的过程。</p>
<p>这些组件被实例化，主要是通过两种方式：</p>
<ol>
<li>直接调用 <code>from_crawler()</code> 进行实例化</li>
<li>通过 <code>scrapy.util.misc.create_instance()</code> 函数进行实例化</li>
</ol>
<p>首先说 1. 直接调用 <code>from_crawler()</code> 进行实例化。</p>
<p>典型的示例如 <code>scrapy.crawler.Crawler</code> 中，对爬虫类 Spider 进行实例化的过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Crawler</span>:</span></span><br><span class="line">   ...</span><br><span class="line">  </span><br><span class="line"><span class="meta">   @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.crawling:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;Crawling already taking place&quot;</span>)</span><br><span class="line">        self.crawling = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.spider = self._create_spider(*args, **kwargs)</span><br><span class="line">            self.engine = self._create_engine()</span><br><span class="line">            start_requests = <span class="built_in">iter</span>(self.spider.start_requests())</span><br><span class="line">            <span class="keyword">yield</span> self.engine.open_spider(self.spider, start_requests)</span><br><span class="line">            <span class="keyword">yield</span> defer.maybeDeferred(self.engine.start)</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            self.crawling = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> self.engine <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">yield</span> self.engine.close()</span><br><span class="line">            <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_spider</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="comment"># 这里直接调用了 spidercls 的 from_crawler 方法，获取 spidercls 的实例</span></span><br><span class="line">        <span class="keyword">return</span> self.spidercls.from_crawler(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_engine</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> ExecutionEngine(self, <span class="keyword">lambda</span> _: self.stop())</span><br><span class="line">      </span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>



<p>在 scrapy 中用到最多的是第二种，通过<code>create_instance()</code> 函数进行实例化.</p>
<p>调用的实例如 scheduler 实例化 dupefilter 的过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scheduler</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        settings = crawler.settings</span><br><span class="line">        dupefilter_cls = load_object(settings[<span class="string">&#x27;DUPEFILTER_CLASS&#x27;</span>])</span><br><span class="line">        <span class="comment"># 这里使用 create_instance 对 dupefilter_cls 进行实例化</span></span><br><span class="line">        dupefilter = create_instance(dupefilter_cls, settings, crawler)</span><br><span class="line">        pqclass = load_object(settings[<span class="string">&#x27;SCHEDULER_PRIORITY_QUEUE&#x27;</span>])</span><br><span class="line">        <span class="keyword">if</span> pqclass <span class="keyword">is</span> PriorityQueue:</span><br><span class="line">            warnings.warn(<span class="string">&quot;SCHEDULER_PRIORITY_QUEUE=&#x27;queuelib.PriorityQueue&#x27;&quot;</span></span><br><span class="line">                          <span class="string">&quot; is no longer supported because of API changes; &quot;</span></span><br><span class="line">                          <span class="string">&quot;please use &#x27;scrapy.pqueues.ScrapyPriorityQueue&#x27;&quot;</span>,</span><br><span class="line">                          ScrapyDeprecationWarning)</span><br><span class="line">            <span class="keyword">from</span> scrapy.pqueues <span class="keyword">import</span> ScrapyPriorityQueue</span><br><span class="line">            pqclass = ScrapyPriorityQueue</span><br><span class="line"></span><br><span class="line">        dqclass = load_object(settings[<span class="string">&#x27;SCHEDULER_DISK_QUEUE&#x27;</span>])</span><br><span class="line">        mqclass = load_object(settings[<span class="string">&#x27;SCHEDULER_MEMORY_QUEUE&#x27;</span>])</span><br><span class="line">        logunser = settings.getbool(<span class="string">&#x27;SCHEDULER_DEBUG&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> cls(dupefilter, jobdir=job_dir(settings), logunser=logunser,</span><br><span class="line">                   stats=crawler.stats, pqclass=pqclass, dqclass=dqclass,</span><br><span class="line">                   mqclass=mqclass, crawler=crawler)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>



<p>那么我们来看下 <code>create_instance</code> 函数内部的实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_instance</span>(<span class="params">objcls, settings, crawler, *args, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Construct a class instance using its ``from_crawler`` or</span></span><br><span class="line"><span class="string">    ``from_settings`` constructors, if available.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    At least one of ``settings`` and ``crawler`` needs to be different from</span></span><br><span class="line"><span class="string">    ``None``. If ``settings `` is ``None``, ``crawler.settings`` will be used.</span></span><br><span class="line"><span class="string">    If ``crawler`` is ``None``, only the ``from_settings`` constructor will be</span></span><br><span class="line"><span class="string">    tried.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ``*args`` and ``**kwargs`` are forwarded to the constructors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises ``ValueError`` if both ``settings`` and ``crawler`` are ``None``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. versionchanged:: 2.2</span></span><br><span class="line"><span class="string">       Raises ``TypeError`` if the resulting instance is ``None`` (e.g. if an</span></span><br><span class="line"><span class="string">       extension has not been implemented correctly).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> settings <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Specify at least one of settings and crawler.&quot;</span>)</span><br><span class="line">        settings = crawler.settings</span><br><span class="line">    <span class="keyword">if</span> crawler <span class="keyword">and</span> <span class="built_in">hasattr</span>(objcls, <span class="string">&#x27;from_crawler&#x27;</span>):</span><br><span class="line">        instance = objcls.from_crawler(crawler, *args, **kwargs)</span><br><span class="line">        method_name = <span class="string">&#x27;from_crawler&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">hasattr</span>(objcls, <span class="string">&#x27;from_settings&#x27;</span>):</span><br><span class="line">        instance = objcls.from_settings(settings, *args, **kwargs)</span><br><span class="line">        method_name = <span class="string">&#x27;from_settings&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        instance = objcls(*args, **kwargs)</span><br><span class="line">        method_name = <span class="string">&#x27;__new__&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> instance <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">f&quot;<span class="subst">&#123;objcls.__qualname__&#125;</span>.<span class="subst">&#123;method_name&#125;</span> returned None&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> instance</span><br></pre></td></tr></table></figure>



<p>逻辑非常清晰明了，根据条件判断调用类的 <code>from_crawler()</code> 方法 或 <code>from_settings()</code> 方法，对类进行实例化，并返回。</p>
<p>同时，这里也可以看到另一个常见的类方法—— <code>from_settings()</code> ，有着和 <code>from_crawler()</code> 相似的作用。</p>
<p>但是如果一个组件是通过 <code>create_instance()</code> 被实例化的, 并且组件内又同时实现了 <code>from_crawler()</code> 和 <code>from_settings()</code> 方法，那么将只有 <code>from_crawler()</code> 方法被调用。</p>
<p>至此, 我们可以对 Scrapy 中常用的 <code>from_crawler()</code> 方法有一个基本的认识.</p>
<br/>

<h2 id="四、参考资料"><a href="#四、参考资料" class="headerlink" title="四、参考资料"></a>四、参考资料</h2><p>[1] <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/index.html">Scrapy documentation</a><br>[2] Scrapy 源码</p>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/Python/" rel="tag">Python</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Scrapy/" rel="tag">Scrapy</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a
                        class="post-action-btn btn btn--disabled"
                        aria-hidden="true"
                    >
                        
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2020/09/14/setting-up-a-k8s-cluster-with-vm/"
                    data-tooltip="使用 Virtualbox 创建 VM k8s 集群"
                    aria-label="下一篇: 使用 Virtualbox 创建 VM k8s 集群"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                    title="分享到 Google+"
                    aria-label="分享到 Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2022 Xavier. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a
                        class="post-action-btn btn btn--disabled"
                        aria-hidden="true"
                    >
                        
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2020/09/14/setting-up-a-k8s-cluster-with-vm/"
                    data-tooltip="使用 Virtualbox 创建 VM k8s 集群"
                    aria-label="下一篇: 使用 Virtualbox 创建 VM k8s 集群"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                    title="分享到 Google+"
                    aria-label="分享到 Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=https://lihanx.github.io/2021/10/25/how-to-use-the-from-crawler-method-in-scrapy/"
                        aria-label="分享到 Google+"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>分享到 Google+</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="作者的图片"/>
        
            <h4 id="about-card-name">Xavier</h4>
        
            <div id="about-card-bio"></div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Python 开发工程师</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover-v1.2.0.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-pwcx44shgfco2srkcnhh8knfc88726ymos4auiuwmqt6fcetpnkbnhqtt4ce.min.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
